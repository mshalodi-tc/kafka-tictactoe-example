---
  version: "3.8"
  services:
    zoo1:
      image: wurstmeister/zookeeper:latest
      hostname: zoo1
      ports:
        - "2181:2181"
      environment:
        ZOO_MY_ID: 1
        ZOO_PORT: 2181
        ZOO_SERVERS: server.1=zoo1:2888:3888
      # Use if you wish to keep data between restarts
      # volumes:
      #   - ./zk-single-kafka-single/zoo1/data:/data
      #   - ./zk-single-kafka-single/zoo1/datalog:/datalog
    kafka1:
      image: wurstmeister/kafka:latest
      hostname: kafka1
      ports:
        - "9092:9092"
      environment:
        KAFKA_LISTENERS: INTERNAL://:19092,EXTERNAL://:9092
        KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka1:19092,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092
        KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
        KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
        KAFKA_ZOOKEEPER_CONNECT: "zoo1:2181"
        KAFKA_AUTHORIZER_CLASS_NAME: "kafka.security.auth.SimpleAclAuthorizer"
        KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
        KAFKA_BROKER_ID: 1
        KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
        KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      # Use if you wish to keep data between restarts
      # volumes:
      #   - ./zk-single-kafka-single/kafka1/data:/var/lib/kafka/data
      depends_on:
        - zoo1
        
    schema-registry:
      image: confluentinc/cp-schema-registry:latest
      restart: always
      hostname: schema-registry
      container_name: schema-registry
      ports:
        - "8081:8081"
      environment:
        SCHEMA_REGISTRY_HOST_NAME: schema-registry
        SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: "kafka1:19092"
      depends_on:
        - zoo1
        - kafka1
  
    connect:
      image: confluentinc/cp-kafka-connect:latest
      hostname: connect
      container_name: connect
      ports:
        - "8083:8083"
      environment:
        CONNECT_PRODUCER_COMPRESSION_TYPE: lz4
        CONNECT_BOOTSTRAP_SERVERS: "kafka1:19092"
        CONNECT_REST_ADVERTISED_HOST_NAME: connect
        CONNECT_REST_LISTENERS: http://0.0.0.0:8083
        CONNECT_REST_PORT: 8083
        CONNECT_GROUP_ID: docker-connect-group
        CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
        CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
        CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
        CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
        CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
        CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
        CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
        CONNECT_KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
        CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
        CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
        CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
        CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
        CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
        # CLASSPATH required due to CC-2422. May need to change the version number depending on the image. Use if using confluent control center
        # CLASSPATH: /usr/share/java/monitoring-interceptors/monitoring-interceptors-6.1.0.jar
        CONNECT_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
        CONNECT_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
        CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components"
        CONNECT_LOG4J_LOGGERS: org.apache.zookeeper=ERROR,org.I0Itec.zkclient=ERROR,org.reflections=ERROR
      depends_on:
        - kafka1
        - schema-registry
        - zoo1
  
    # Within tucows we do not use confluent control center. instead we use akhq as an alternative.
    akhq:
      image: tchiotludo/akhq:latest
      environment:
        AKHQ_CONFIGURATION: |
          akhq:
            connections:
              docker-kafka-server-1:
                properties:
                  bootstrap.servers: "kafka1:19092"
                schema-registry:
                  url: "http://schema-registry:8081"
                connect:
                  - name: connect-1
                    url: "http://connect:8083"
      ports:
        - 8080:8080
      links:
        - kafka1
        - schema-registry
        - connect

    tic-tac-toe:
      build:
        context: ./src